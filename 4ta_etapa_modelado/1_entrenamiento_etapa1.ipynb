{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de91ea37",
   "metadata": {},
   "source": [
    "# Entrenamiento Etapa 1: Predicción Binaria (¿Habrá Réplica Fuerte?)\n",
    "\n",
    "## Objetivo\n",
    "Entrenar dos modelos (Decision Tree y kNN) para predecir si habrá una réplica importante después de un terremoto principal.\n",
    "\n",
    "**Target:** `existe_replica_fuerte` (1 = Sí habrá, 0 = No habrá)\n",
    "\n",
    "**Algoritmos:**\n",
    "- Decision Tree (Árbol de decisión)\n",
    "- kNN (K-vecinos más cercanos)\n",
    "\n",
    "**Validación:** Temporal (entrenar con eventos antiguos, testear con recientes)\n",
    "\n",
    "## Estrategia de Desbalance de Clases\n",
    "\n",
    "**Decisión:** NO usar SMOTE ni oversampling manual.\n",
    "\n",
    "**Método:** Usar `class_weight='balanced'` en modelos que lo soporten.\n",
    "\n",
    "**Razón:**\n",
    "- SMOTE puede crear datos sintéticos que no representan sismos reales.\n",
    "- `class_weight='balanced'` ajusta automáticamente los pesos para dar más importancia a la clase minoritaria (réplicas fuertes) sin inventar datos.\n",
    "- Para kNN (que no tiene class_weight), usamos `weights='distance'` que da más peso a vecinos cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35402835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Utilidades propias\n",
    "import sys\n",
    "sys.path.append('..')  # Para importar desde carpeta superior si fuera necesario\n",
    "from utils_validacion import (\n",
    "    limpiar_columnas_vacias,\n",
    "    split_temporal,\n",
    "    preparar_train_test,\n",
    "    obtener_columnas_numericas\n",
    ")\n",
    "\n",
    "# Configuración visual\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print('Librerías importadas correctamente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1f6a7",
   "metadata": {},
   "source": [
    "## 1. Cargar y Limpiar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a43caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Etapa 1: 236 terremotos principales (mainshocks)\n",
      "Columnas: 29\n",
      "[Limpieza] Columnas 100% NaN eliminadas: ['similitud_promedio_vecinos', 'conflicto_modelos']\n",
      "\n",
      "Distribución de réplicas fuertes:\n",
      "existe_replica_fuerte\n",
      "0    211\n",
      "1     25\n",
      "Name: count, dtype: int64\n",
      "Porcentaje con réplica: 10.6%\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset maestro\n",
    "master = pd.read_csv('../3ra_etapa_preprocesamiento/seismic_features_fusion_final.csv')\n",
    "\n",
    "# Filtrar solo mainshocks (Etapa 1)\n",
    "etapa1 = master[master['es_mainshock'] == 1].copy()\n",
    "\n",
    "print(f'Dataset Etapa 1: {etapa1.shape[0]} terremotos principales (mainshocks)')\n",
    "print(f'Columnas: {etapa1.shape[1]}')\n",
    "\n",
    "# Limpiar columnas totalmente vacías\n",
    "etapa1, cols_eliminadas = limpiar_columnas_vacias(etapa1)\n",
    "\n",
    "# Verificar distribución del target\n",
    "print('\\nDistribución de réplicas fuertes:')\n",
    "print(etapa1['existe_replica_fuerte'].value_counts())\n",
    "print(f\"Porcentaje con réplica: {etapa1['existe_replica_fuerte'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb776b",
   "metadata": {},
   "source": [
    "## 2. División Temporal (Train/Test)\n",
    "\n",
    "**Nota:** No usamos oversampling (SMOTE) ni balanceo manual de clases. En su lugar, configuramos `class_weight='balanced'` en los modelos para que automáticamente den más peso a la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporal: 70% entrenamiento (eventos antiguos), 30% prueba (eventos recientes)\n",
    "train, test = split_temporal(etapa1, col_fecha='Date(UTC)', porcentaje_train=0.7)\n",
    "\n",
    "# Verificar balance en cada conjunto\n",
    "print('\\nBalance en Train:')\n",
    "print(train['existe_replica_fuerte'].value_counts(normalize=True))\n",
    "print('\\nBalance en Test:')\n",
    "print(test['existe_replica_fuerte'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e66723",
   "metadata": {},
   "source": [
    "## 3. Preparar Features y Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener columnas numéricas (excluyendo targets y fecha)\n",
    "columnas_features = obtener_columnas_numericas(etapa1)\n",
    "\n",
    "print(f'\\nFeatures seleccionadas: {len(columnas_features)}')\n",
    "print(columnas_features[:10], '...')  # Mostrar primeras 10\n",
    "\n",
    "# Preparar conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test, scaler = preparar_train_test(\n",
    "    train, test,\n",
    "    columnas_features=columnas_features,\n",
    "    col_target='existe_replica_fuerte'\n",
    ")\n",
    "\n",
    "print(f'\\nFormas finales:')\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9f9b8",
   "metadata": {},
   "source": [
    "## 4. Entrenar Decision Tree (Árbol de Decisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81af961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar modelo Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=10,           # Profundidad máxima (evita sobreajuste)\n",
    "    min_samples_split=10,   # Mínimo de muestras para dividir un nodo\n",
    "    min_samples_leaf=5,     # Mínimo de muestras en una hoja\n",
    "    class_weight='balanced', # Ajusta pesos para manejar desbalance (en vez de SMOTE/oversampling)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print('Entrenando Decision Tree...')\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print('✓ Modelo Decision Tree entrenado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b2533",
   "metadata": {},
   "source": [
    "## 5. Entrenar kNN (K-Vecinos Más Cercanos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar modelo kNN\n",
    "# Nota: kNN no tiene class_weight, pero usamos weights='distance' \n",
    "# que da más importancia a vecinos cercanos (ayuda con desbalance)\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=5,      # Número de vecinos a consultar\n",
    "    weights='distance', # Vecinos más cercanos tienen más peso (alternativa a class_weight)\n",
    "    metric='euclidean'  # Métrica de distancia\n",
    ")\n",
    "\n",
    "print('Entrenando kNN...')\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print('✓ Modelo kNN entrenado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e624f9",
   "metadata": {},
   "source": [
    "## 6. Evaluar Modelos: Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular y mostrar métricas\n",
    "def evaluar_modelo(y_true, y_pred, nombre_modelo):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'\\n═══ Métricas: {nombre_modelo} ═══')\n",
    "    print(f'Accuracy (Aciertos totales):  {acc:.3f} ({acc*100:.1f}%)')\n",
    "    print(f'Precision (¿Cuántas alarmas son correctas?): {prec:.3f}')\n",
    "    print(f'Recall (¿Cuántas réplicas reales detecta?):   {rec:.3f}')\n",
    "    print(f'F1-Score (Balance precision/recall):         {f1:.3f}')\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "\n",
    "# Evaluar Decision Tree\n",
    "metricas_dt = evaluar_modelo(y_test, y_pred_dt, 'Decision Tree')\n",
    "\n",
    "# Evaluar kNN\n",
    "metricas_knn = evaluar_modelo(y_test, y_pred_knn, 'kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd3b77",
   "metadata": {},
   "source": [
    "## 7. Matrices de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar matriz de confusión\n",
    "def plot_confusion_matrix(y_true, y_pred, titulo):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Réplica', 'Sí Réplica'],\n",
    "                yticklabels=['No Réplica', 'Sí Réplica'])\n",
    "    plt.title(titulo)\n",
    "    plt.ylabel('Real')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretar matriz\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f'\\nInterpretación:')\n",
    "    print(f'  Verdaderos Negativos (TN): {tn} - Correctamente predijo \"No habrá réplica\"')\n",
    "    print(f'  Falsos Positivos (FP):     {fp} - Dijo \"Sí\" pero no hubo réplica (falsa alarma)')\n",
    "    print(f'  Falsos Negativos (FN):     {fn} - Dijo \"No\" pero sí hubo réplica (¡PELIGROSO!)')\n",
    "    print(f'  Verdaderos Positivos (TP): {tp} - Correctamente predijo \"Sí habrá réplica\"')\n",
    "\n",
    "# Graficar Decision Tree\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Matriz de Confusión - Decision Tree')\n",
    "\n",
    "# Graficar kNN\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'Matriz de Confusión - kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85ada6",
   "metadata": {},
   "source": [
    "## 8. Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a992e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame comparativo\n",
    "comparacion = pd.DataFrame({\n",
    "    'Decision Tree': metricas_dt,\n",
    "    'kNN': metricas_knn\n",
    "})\n",
    "\n",
    "print('\\n═══ Comparación de Modelos ═══')\n",
    "print(comparacion.T.round(3))\n",
    "\n",
    "# Gráfico de barras\n",
    "comparacion.T.plot(kind='bar', figsize=(10, 5))\n",
    "plt.title('Comparación de Métricas: Decision Tree vs kNN')\n",
    "plt.ylabel('Valor')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Métrica')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e480c68",
   "metadata": {},
   "source": [
    "## 9. Conclusiones Etapa 1\n",
    "\n",
    "### Interpretación de Resultados\n",
    "\n",
    "**Accuracy:** Porcentaje total de aciertos (incluye predicciones correctas de \"No\" y \"Sí\").\n",
    "\n",
    "**Precision:** De las veces que el modelo dijo \"Sí habrá réplica\", ¿cuántas acertó?\n",
    "- Alta precision = Pocas falsas alarmas.\n",
    "\n",
    "**Recall:** De todas las réplicas reales, ¿cuántas detectó?\n",
    "- Alto recall = Detecta la mayoría de réplicas (crítico para seguridad).\n",
    "\n",
    "**F1-Score:** Balance entre precision y recall.\n",
    "\n",
    "### ¿Cuál Modelo Usar?\n",
    "\n",
    "- Si **Recall** es más importante (no queremos perder réplicas reales) → Elegir modelo con mayor Recall.\n",
    "- Si **Precision** es más importante (evitar falsas alarmas) → Elegir modelo con mayor Precision.\n",
    "- Para balance → Elegir modelo con mayor **F1-Score**.\n",
    "\n",
    "### Próximos Pasos\n",
    "\n",
    "1. **Ajustar parámetros** del mejor modelo (profundidad del árbol, número de vecinos).\n",
    "2. **Probar variantes de features** (todas vs PCA vs top correlación).\n",
    "3. **Pasar a Etapa 2:** Entrenar modelos para predecir ventana temporal (0-24h, 24-72h, >72h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos entrenados (opcional)\n",
    "import joblib\n",
    "\n",
    "joblib.dump(dt_model, 'decision_tree_etapa1.pkl')\n",
    "joblib.dump(knn_model, 'knn_etapa1.pkl')\n",
    "joblib.dump(scaler, 'scaler_etapa1.pkl')\n",
    "\n",
    "print('\\n✓ Modelos guardados:')\n",
    "print('  - decision_tree_etapa1.pkl')\n",
    "print('  - knn_etapa1.pkl')\n",
    "print('  - scaler_etapa1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
